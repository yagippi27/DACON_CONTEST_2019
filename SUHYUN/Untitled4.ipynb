{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\workspace\\\\DACON_2019\\\\SUHYUN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\workspace\\\\DACON_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X26</th>\n",
       "      <th>X303</th>\n",
       "      <th>X241</th>\n",
       "      <th>X435</th>\n",
       "      <th>X402</th>\n",
       "      <th>X352</th>\n",
       "      <th>X305</th>\n",
       "      <th>X350</th>\n",
       "      <th>X326</th>\n",
       "      <th>...</th>\n",
       "      <th>X283</th>\n",
       "      <th>X329</th>\n",
       "      <th>X223</th>\n",
       "      <th>X266</th>\n",
       "      <th>X20</th>\n",
       "      <th>X443</th>\n",
       "      <th>X347</th>\n",
       "      <th>X75</th>\n",
       "      <th>X107</th>\n",
       "      <th>X230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-01 00:00:00</td>\n",
       "      <td>1.187315</td>\n",
       "      <td>0.385586</td>\n",
       "      <td>0.298691</td>\n",
       "      <td>0.276657</td>\n",
       "      <td>0.190045</td>\n",
       "      <td>0.160754</td>\n",
       "      <td>0.343880</td>\n",
       "      <td>0.249761</td>\n",
       "      <td>0.070329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288141</td>\n",
       "      <td>0.326095</td>\n",
       "      <td>0.356141</td>\n",
       "      <td>0.407326</td>\n",
       "      <td>0.159644</td>\n",
       "      <td>0.227077</td>\n",
       "      <td>0.168175</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.338138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-01 01:00:00</td>\n",
       "      <td>1.186123</td>\n",
       "      <td>0.478955</td>\n",
       "      <td>0.307983</td>\n",
       "      <td>0.333324</td>\n",
       "      <td>0.193712</td>\n",
       "      <td>0.167303</td>\n",
       "      <td>0.426744</td>\n",
       "      <td>0.293231</td>\n",
       "      <td>0.072641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259911</td>\n",
       "      <td>0.297695</td>\n",
       "      <td>0.296728</td>\n",
       "      <td>0.316149</td>\n",
       "      <td>0.159288</td>\n",
       "      <td>0.259118</td>\n",
       "      <td>0.184568</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.335306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-07-01 02:00:00</td>\n",
       "      <td>1.168301</td>\n",
       "      <td>0.467760</td>\n",
       "      <td>0.323560</td>\n",
       "      <td>0.331767</td>\n",
       "      <td>0.200656</td>\n",
       "      <td>0.165983</td>\n",
       "      <td>0.405878</td>\n",
       "      <td>0.301436</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237175</td>\n",
       "      <td>0.261525</td>\n",
       "      <td>0.288334</td>\n",
       "      <td>0.267332</td>\n",
       "      <td>0.157027</td>\n",
       "      <td>0.267059</td>\n",
       "      <td>0.177599</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.344922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017-07-01 03:00:00</td>\n",
       "      <td>1.163425</td>\n",
       "      <td>0.443529</td>\n",
       "      <td>0.304879</td>\n",
       "      <td>0.322123</td>\n",
       "      <td>0.189067</td>\n",
       "      <td>0.155355</td>\n",
       "      <td>0.401216</td>\n",
       "      <td>0.288693</td>\n",
       "      <td>0.082617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203332</td>\n",
       "      <td>0.207759</td>\n",
       "      <td>0.253232</td>\n",
       "      <td>0.212221</td>\n",
       "      <td>0.154466</td>\n",
       "      <td>0.251081</td>\n",
       "      <td>0.156110</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.334552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-07-01 04:00:00</td>\n",
       "      <td>1.398466</td>\n",
       "      <td>0.390286</td>\n",
       "      <td>0.322174</td>\n",
       "      <td>0.320922</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>0.154073</td>\n",
       "      <td>0.344145</td>\n",
       "      <td>0.295861</td>\n",
       "      <td>0.074067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189208</td>\n",
       "      <td>0.174952</td>\n",
       "      <td>0.266133</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.152014</td>\n",
       "      <td>0.253930</td>\n",
       "      <td>0.143873</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.346241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8755</td>\n",
       "      <td>2018-06-30 19:00:00</td>\n",
       "      <td>1.255000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>11.546000</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>3.519</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8756</td>\n",
       "      <td>2018-06-30 20:00:00</td>\n",
       "      <td>1.596000</td>\n",
       "      <td>1.692000</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>11.591000</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>3.331</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8757</td>\n",
       "      <td>2018-06-30 21:00:00</td>\n",
       "      <td>1.379000</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.659000</td>\n",
       "      <td>10.766000</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>3.416</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8758</td>\n",
       "      <td>2018-06-30 22:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>4.263</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8759</td>\n",
       "      <td>2018-06-30 23:00:00</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.519000</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time       X26      X303      X241      X435      X402  \\\n",
       "0     2017-07-01 00:00:00  1.187315  0.385586  0.298691  0.276657  0.190045   \n",
       "1     2017-07-01 01:00:00  1.186123  0.478955  0.307983  0.333324  0.193712   \n",
       "2     2017-07-01 02:00:00  1.168301  0.467760  0.323560  0.331767  0.200656   \n",
       "3     2017-07-01 03:00:00  1.163425  0.443529  0.304879  0.322123  0.189067   \n",
       "4     2017-07-01 04:00:00  1.398466  0.390286  0.322174  0.320922  0.195500   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "8755  2018-06-30 19:00:00  1.255000  0.175000  0.430000  0.429000  0.169000   \n",
       "8756  2018-06-30 20:00:00  1.596000  1.692000  0.332000  0.366000  0.159000   \n",
       "8757  2018-06-30 21:00:00  1.379000  0.883000  0.435000  0.497000  0.166000   \n",
       "8758  2018-06-30 22:00:00  1.000000  0.539000  0.268000  0.459000  0.463000   \n",
       "8759  2018-06-30 23:00:00  0.976000  0.481000  0.220000  0.418000  0.646000   \n",
       "\n",
       "          X352      X305      X350      X326  ...      X283      X329  \\\n",
       "0     0.160754  0.343880  0.249761  0.070329  ...  0.288141  0.326095   \n",
       "1     0.167303  0.426744  0.293231  0.072641  ...  0.259911  0.297695   \n",
       "2     0.165983  0.405878  0.301436  0.076477  ...  0.237175  0.261525   \n",
       "3     0.155355  0.401216  0.288693  0.082617  ...  0.203332  0.207759   \n",
       "4     0.154073  0.344145  0.295861  0.074067  ...  0.189208  0.174952   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "8755  0.739000  0.573000  0.341000  0.127000  ...  0.312000  0.381000   \n",
       "8756  0.255000  0.501000  0.281000  0.126000  ...  0.327000  0.402000   \n",
       "8757  0.233000  0.634000  0.401000  0.439000  ...  0.253000  0.401000   \n",
       "8758  0.454000  0.676000  0.543000  0.737000  ...  0.332000  0.401000   \n",
       "8759  0.419000  0.680000  0.499000  0.304000  ...  0.434000  0.435000   \n",
       "\n",
       "          X223      X266        X20      X443      X347    X75   X107  \\\n",
       "0     0.356141  0.407326   0.159644  0.227077  0.168175  0.275  0.021   \n",
       "1     0.296728  0.316149   0.159288  0.259118  0.184568  0.222  0.021   \n",
       "2     0.288334  0.267332   0.157027  0.267059  0.177599  0.237  0.021   \n",
       "3     0.253232  0.212221   0.154466  0.251081  0.156110  0.229  0.020   \n",
       "4     0.266133  0.244444   0.152014  0.253930  0.143873  0.202  0.021   \n",
       "...        ...       ...        ...       ...       ...    ...    ...   \n",
       "8755  0.479000  0.858000  11.546000  0.428000  0.134000  3.519  0.027   \n",
       "8756  0.725000  0.816000  11.591000  0.413000  0.206000  3.331  0.027   \n",
       "8757  0.426000  0.659000  10.766000  0.466000  0.324000  3.416  0.026   \n",
       "8758  0.353000  0.462000   0.312000  0.473000  0.402000  4.263  0.027   \n",
       "8759  0.349000  0.792000   0.309000  0.519000  0.334000  0.784  0.027   \n",
       "\n",
       "          X230  \n",
       "0     0.338138  \n",
       "1     0.335306  \n",
       "2     0.344922  \n",
       "3     0.334552  \n",
       "4     0.346241  \n",
       "...        ...  \n",
       "8755  0.286000  \n",
       "8756  0.303000  \n",
       "8757  0.253000  \n",
       "8758  0.253000  \n",
       "8759  0.310000  \n",
       "\n",
       "[8760 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('.\\\\SOOMIN\\\\data\\\\Test_시간별평균대치.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(signal_data, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(signal_data)-look_back):\n",
    "        dataX.append(signal_data[i:(i+look_back), 0])\n",
    "        dataY.append(signal_data[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "class CustomHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Time'] = pd.to_datetime(test['Time']) \n",
    "test = test.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_data = test.iloc[:, 0].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "signal_data = scaler.fit_transform(signal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "train = signal_data[:5256]\n",
    "val = signal_data[5256:7008]\n",
    "test = signal_data[7008:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_val, y_val = create_dataset(val, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "for i in range(2):\n",
    "    model.add(LSTM(32, batch_input_shape=(1, look_back, 1), stateful=True, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, batch_input_shape=(1, look_back, 1), stateful=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-c4b2f90621c3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-c4b2f90621c3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    early_callback =\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "early_callback = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모델 학습시키기\n",
    "custom_hist = CustomHistory()\n",
    "custom_hist.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 5232 samples, validate on 1728 samples\n",
      "Epoch 1/1\n",
      "5232/5232 [==============================] - 153s 29ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Train on 5232 samples, validate on 1728 samples\n",
      "Epoch 1/1\n",
      "5232/5232 [==============================] - 182s 35ms/step - loss: 7.0152e-04 - val_loss: 2.4618e-04\n",
      "Train on 5232 samples, validate on 1728 samples\n",
      "Epoch 1/1\n",
      "5232/5232 [==============================] - 197s 38ms/step - loss: 3.1818e-04 - val_loss: 3.0421e-04\n",
      "Train on 5232 samples, validate on 1728 samples\n",
      "Epoch 1/1\n",
      " 862/5232 [===>..........................] - ETA: 2:36 - loss: 3.0433e-04- ETA: 2:38 - lo"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model.fit(x_train, y_train, epochs=1, batch_size=batch_size, shuffle=False, callbacks=[custom_hist], validation_data=(x_val, y_val))\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making_shift_count = 25\n",
    "\n",
    "# dataset = Series_data.to_frame()\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# dataset_sc=MinMaxScaler().fit_transform(dataset)\n",
    "# dataset_sc_df = pd.DataFrame(dataset_sc, columns=dataset.columns, index = dataset.index)\n",
    "\n",
    "# for s in range(1, making_shift_count):\n",
    "#     dataset_sc_df['shift_{}'.format(s)] = dataset_sc_df[dataset.columns].shift(s)\n",
    "\n",
    "# X_dataset = dataset_sc_df.dropna().drop(dataset.columns, axis=1)\n",
    "# y_dataset = dataset_sc_df.dropna()[dataset.columns]\n",
    "\n",
    "# X_dataset = X_dataset.values\n",
    "# y_dataset = y_dataset.values\n",
    "\n",
    "# X_dataset_t = X_dataset.reshape(X_dataset.shape[0], making_shift_count-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "import keras.backend as K \n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "    \n",
    "model = Sequential() # Sequeatial Model \n",
    "model.add(LSTM(20, input_shape=(X_dataset_t.shape[1], 1))) # (timestep, feature) \n",
    "model.add(Dense(1)) # output = 1 \n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=1, verbose=1)\n",
    "\n",
    "history = model.fit(X_dataset_t, y_dataset, epochs=100, batch_size=30, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vloss=history.history['val_loss'] # 오차 표시를 위해 저장\n",
    "y_acc=history.history['acc'] # 정확도 표시를 위해 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3) # 빨간색은 오차\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3) # 파란색은 정확도\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
